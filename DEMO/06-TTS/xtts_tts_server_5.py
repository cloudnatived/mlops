#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import torch
import numpy as np
import pandas as pd
import gradio as gr
from TTS.api import TTS
import logging
import pkg_resources

# ---------------- é…ç½®æ—¥å¿— ----------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ---------------- é…ç½®Hugging Faceç¼“å­˜ ----------------
os.environ["HF_HOME"] = "/Data/MODEL/cache"
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["TTS_HOME"] = "/Data/MODEL/coqui/XTTS-v2"

# ---------------- è®¾å¤‡ & XTTSæ¨¡å‹é…ç½® ----------------
device = "cuda" if torch.cuda.is_available() else "cpu"
logger.info(f"ä½¿ç”¨è®¾å¤‡: {device} | GPUæ•°é‡: {torch.cuda.device_count()}")

MODEL_PATH = "/Data/MODEL/coqui/XTTS-v2"

try:
    model = TTS(model_path=MODEL_PATH, config_path=os.path.join(MODEL_PATH, "config.json"), progress_bar=True)
    model.to(device)
    logger.info(f"âœ… æˆåŠŸåŠ è½½XTTSæ¨¡å‹: {MODEL_PATH}")
except Exception as e:
    logger.error(f"âŒ åŠ è½½XTTSæ¨¡å‹å¤±è´¥: {str(e)}", exc_info=True)
    raise RuntimeError(f"âŒ åŠ è½½XTTSæ¨¡å‹å¤±è´¥: {str(e)}") from e

# ---------------- æ ¸å¿ƒé…ç½®å‚æ•° ----------------
BATCH_SIZE = 2  # V100 16GB å»ºè®®å°æ‰¹é‡
LANGUAGE = "zh"  # æ”¯æŒä¸­æ–‡
AUDIO_EXTENSIONS = (".wav", ".mp3")  # æ”¯æŒçš„å‚è€ƒéŸ³é¢‘æ ¼å¼

# ---------------- 1. æ–‡æœ¬å’ŒéŸ³é¢‘å¤„ç†å·¥å…·å‡½æ•° ----------------
def validate_text(text: str) -> str:
    """éªŒè¯å¹¶æ¸…ç†è¾“å…¥æ–‡æœ¬"""
    if not text.strip():
        raise ValueError("è¾“å…¥æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    return text.strip()

def validate_audio(file_path: str) -> str:
    """éªŒè¯å‚è€ƒéŸ³é¢‘æ–‡ä»¶"""
    if not file_path:
        raise ValueError("è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼ˆWAVæˆ–MP3ï¼‰")
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    if not file_path.lower().endswith(AUDIO_EXTENSIONS):
        raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {file_path}ï¼ˆä»…æ”¯æŒ{AUDIO_EXTENSIONS}ï¼‰")
    return file_path

# ---------------- 2. æ‰¹é‡TTSå‡½æ•° ----------------
def batch_tts(texts: list, speaker_wav: str, progress=gr.Progress()) -> tuple:
    """
    æ‰¹é‡æ–‡æœ¬è½¬è¯­éŸ³æ ¸å¿ƒå‡½æ•°
    å‚æ•°ï¼štexts (è¾“å…¥æ–‡æœ¬åˆ—è¡¨), speaker_wav (å‚è€ƒéŸ³é¢‘è·¯å¾„)
    è¿”å›ï¼š(TTSç»“æœåˆ—è¡¨, éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨)
    """
    if not texts:
        return [], []
    
    progress(0, desc="åˆå§‹åŒ–TTSä»»åŠ¡...")
    total_texts = len(texts)
    all_results = []
    audio_paths = []

    audio_temp_dir = f"/tmp/xtts_audio_{int(time.time())}"
    os.makedirs(audio_temp_dir, exist_ok=True)

    try:
        # éªŒè¯å‚è€ƒéŸ³é¢‘
        speaker_wav = validate_audio(speaker_wav) if speaker_wav else None
        
        for i, batch_idx in enumerate(range(0, total_texts, BATCH_SIZE)):
            progress(i / (total_texts // BATCH_SIZE + 1), desc=f"å¤„ç†æ‰¹æ¬¡ {i+1}/{(total_texts // BATCH_SIZE + 1)}")
            batch_texts = texts[batch_idx:batch_idx + BATCH_SIZE]
            
            for idx, text in enumerate(batch_texts):
                try:
                    validated_text = validate_text(text)
                    audio_path = os.path.join(audio_temp_dir, f"tts_{batch_idx + idx}.wav")
                    
                    model.tts_to_file(
                        text=validated_text,
                        file_path=audio_path,
                        speaker_wav=speaker_wav,
                        language=LANGUAGE
                    )
                    
                    all_results.append({
                        "text": validated_text,
                        "audio_path": audio_path
                    })
                    audio_paths.append(audio_path)
                
                except Exception as inner_e:
                    logger.error(f"TTSå¤„ç†æ–‡æœ¬å¤±è´¥: {text} | é”™è¯¯: {str(inner_e)}", exc_info=True)
                    raise RuntimeError(f"TTSå¤„ç†æ–‡æœ¬å¤±è´¥: {text} | é”™è¯¯: {str(inner_e)}") from inner_e

        return all_results, audio_paths

    except Exception as e:
        logger.error(f"TTSè¿‡ç¨‹å‡ºé”™: {str(e)}", exc_info=True)
        raise RuntimeError(f"TTSè¿‡ç¨‹å‡ºé”™: {str(e)}") from e

# ---------------- 3. Gradio UIäº¤äº’é€»è¾‘ ----------------
def create_ui() -> gr.Blocks:
    """åˆ›å»ºGradio UIï¼Œå…¼å®¹ Gradio 3.xï¼Œæ·»åŠ å‚è€ƒéŸ³é¢‘ä¸Šä¼ """
    with gr.Blocks(title="XTTSæ‰¹é‡æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆåŒV100ä¼˜åŒ–ç‰ˆï¼‰") as demo:
        gr.Markdown("# ğŸš€ XTTSæ‰¹é‡æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆåŒV100åŠ é€Ÿï¼‰")
        gr.Markdown(f"""
        - æ”¯æŒè¾“å…¥ï¼šå¤šè¡Œæ–‡æœ¬ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰
        - æ”¯æŒå‚è€ƒéŸ³é¢‘ï¼šWAV/MP3ï¼ˆç”¨äºå£°éŸ³å…‹éš†ï¼‰
        - é…ç½®ï¼šæ‰¹é‡å¤§å°{BATCH_SIZE} | è¯­è¨€{LANGUAGE}
        - è®¾å¤‡ï¼š{device}ï¼ˆ{torch.cuda.device_count()}å¼ GPUï¼‰
        """)

        with gr.Row():
            text_input = gr.Textbox(
                lines=10,
                placeholder="è¾“å…¥æ–‡æœ¬ï¼Œæ¯è¡Œä¸€æ¡ï¼ˆä¾‹å¦‚ï¼š\nè¯»ä¸€æ®µå°è¯è¯•è¯•\nè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ï¼‰",
                label="ğŸ“¤ è¾“å…¥æ–‡æœ¬ï¼ˆæ”¯æŒå¤šè¡Œï¼‰",
                elem_id="text-input"
            )
            audio_input = gr.File(
                file_count="single",
                file_types=[".wav", ".mp3"],
                label="ğŸ™ï¸ ä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼ˆWAVæˆ–MP3ï¼Œç”¨äºå£°éŸ³å…‹éš†ï¼‰"
            )

        with gr.Row():
            run_btn = gr.Button("â–¶ï¸ å¼€å§‹æ‰¹é‡è½¬æ¢", variant="primary", size="lg")

        with gr.Row():
            result_table = gr.Dataframe(
                headers=["è¾“å…¥æ–‡æœ¬", "éŸ³é¢‘æ–‡ä»¶"],
                datatype=["str", "str"],
                label="ğŸ“Š TTSç»“æœè¡¨æ ¼"
            )
            audio_preview = gr.Audio(
                label="ğŸ–¼ï¸ éŸ³é¢‘ç»“æœé¢„è§ˆï¼ˆå¯æ’­æ”¾/ä¸‹è½½ï¼‰",
                interactive=False
            )
            zip_output = gr.File(label="ğŸ’¾ ä¸‹è½½æ‰€æœ‰éŸ³é¢‘ï¼ˆZIPï¼‰")

        def handle_tts(input_text: str, audio_file) -> tuple:
            """å¤„ç†TTSè¯·æ±‚ï¼šè§£ææ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘â†’æ‰¹é‡è½¬æ¢â†’ç”Ÿæˆç»“æœ"""
            if not input_text.strip():
                raise gr.Error("è¯·å…ˆè¾“å…¥æ–‡æœ¬ï¼")
            
            texts = [line.strip() for line in input_text.split("\n") if line.strip()]
            speaker_wav = audio_file.name if audio_file else None
            all_results, audio_paths = batch_tts(texts, speaker_wav)
            if not all_results:
                raise gr.Error("æœªç”Ÿæˆä»»ä½•éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥è¾“å…¥æ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘ï¼")
            
            pandas_version = pkg_resources.get_distribution("pandas").version
            if pkg_resources.parse_version(pandas_version) >= pkg_resources.parse_version("2.2.0"):
                with pd.option_context("future.no_silent_downcasting", True):
                    table_data = [[res["text"], res["audio_path"]] for res in all_results]
            else:
                table_data = [[res["text"], res["audio_path"]] for res in all_results]
            
            zip_path = f"/tmp/xtts_audio_result_{int(time.time())}.zip"
            import zipfile
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                for audio in audio_paths:
                    zipf.write(audio, os.path.basename(audio))

            return table_data, audio_paths[0] if audio_paths else None, zip_path

        run_btn.click(
            fn=handle_tts,
            inputs=[text_input, audio_input],
            outputs=[result_table, audio_preview, zip_output],
            show_progress=True
        )

    return demo

# ---------------- 4. å¯åŠ¨ç¨‹åº ----------------
if __name__ == "__main__":
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7864,
        share=False,
        debug=False
    )
