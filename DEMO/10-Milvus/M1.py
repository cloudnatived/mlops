#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# M1.py - å…¼å®¹å¤šç‰ˆæœ¬PyTorchçš„Milvuså¤šæ¨¡æ€ç¤ºä¾‹
from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType
import numpy as np
from pymilvus import utility
import random
import os
import sys
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# 1. å®šä¹‰Identityç±»ï¼ˆç”¨äºæ›¿æ¢ResNetçš„å…¨è¿æ¥å±‚ï¼‰
class Identity(nn.Module):
    def __init__(self):
        super(Identity, self).__init__()
        
    def forward(self, x):
        return x

# 2. å…¼å®¹æ€§å¯¼å…¥å’Œç‰ˆæœ¬æ£€æŸ¥
def setup_environment():
    """è®¾ç½®ç¯å¢ƒï¼Œå¤„ç†ä¸åŒç‰ˆæœ¬çš„PyTorchå’Œæ¨¡å‹åŠ è½½"""
    
    # æ£€æŸ¥PyTorchæ˜¯å¦å¯ç”¨
    try:
        import torch
        import torchvision
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        logger.info(f"Torchvisionç‰ˆæœ¬: {torchvision.__version__}")
    except ImportError as e:
        logger.error("æœªå®‰è£…PyTorchï¼Œè¯·å…ˆå®‰è£…: pip install torch torchvision")
        sys.exit(1)
    
    # å°è¯•å¯¼å…¥sentence-transformersï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    text_encoder = None
    try:
        from sentence_transformers import SentenceTransformer
        text_encoder = SentenceTransformer('all-MiniLM-L6-v2')
        logger.info("âœ… æˆåŠŸåŠ è½½sentence-transformers")
    except ImportError as e:
        logger.warning("âŒ æ— æ³•å¯¼å…¥sentence-transformersï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–‡æœ¬ç¼–ç æ–¹æ¡ˆ")
        logger.warning(f"é”™è¯¯ä¿¡æ¯: {e}")
    except Exception as e:
        logger.warning(f"âŒ sentence-transformersåŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    
    return text_encoder

# 3. å¤‡ç”¨æ–‡æœ¬ç¼–ç æ–¹æ¡ˆ
class BackupTextEncoder:
    """å½“sentence-transformersä¸å¯ç”¨æ—¶ä½¿ç”¨çš„å¤‡ç”¨æ–‡æœ¬ç¼–ç å™¨"""
    
    def __init__(self, dim=384):
        self.dim = dim
        logger.info(f"ä½¿ç”¨å¤‡ç”¨æ–‡æœ¬ç¼–ç å™¨ï¼Œç»´åº¦: {dim}")
    
    def encode(self, text):
        """ç”Ÿæˆéšæœºæ–‡æœ¬å‘é‡ï¼ˆç”Ÿäº§ç¯å¢ƒä¸­åº”æ›¿æ¢ä¸ºæ›´åˆç†çš„ç¼–ç æ–¹æ³•ï¼‰"""
        # è¿™é‡Œä½¿ç”¨åŸºäºæ–‡æœ¬å“ˆå¸Œçš„ç¡®å®šæ€§éšæœºå‘é‡
        import hashlib
        seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
        rng = np.random.RandomState(seed)
        return rng.randn(self.dim).astype(np.float32)

# 4. æ”¹è¿›çš„æ–‡æœ¬åµŒå…¥å‡½æ•°
def get_text_embedding(text, text_encoder=None):
    """å…¼å®¹å¤šç§æƒ…å†µçš„æ–‡æœ¬åµŒå…¥å‡½æ•°"""
    if text_encoder is not None:
        try:
            # ä½¿ç”¨sentence-transformers
            embedding = text_encoder.encode(text)
            return embedding.astype(np.float32)
        except Exception as e:
            logger.warning(f"sentence-transformersç¼–ç å¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
    
    # ä½¿ç”¨å¤‡ç”¨ç¼–ç å™¨
    backup_encoder = BackupTextEncoder()
    return backup_encoder.encode(text)

# 5. è¡¨æ ¼æ•°æ®å¤„ç†ï¼ˆæ”¹è¿›ç‰ˆï¼‰
def get_tabular_embedding(tabular_data, method="random"):
    """ç”Ÿæˆè¡¨æ ¼æ•°æ®å‘é‡ï¼Œæ”¯æŒå¤šç§æ–¹æ³•"""
    if method == "random":
        # éšæœºå‘é‡ï¼ˆé»˜è®¤ï¼‰
        return np.random.random(128).astype(np.float32)
    elif method == "hash_based":
        # åŸºäºæ•°æ®å“ˆå¸Œçš„ç¡®å®šæ€§å‘é‡
        import hashlib
        data_str = str(tabular_data)
        seed = int(hashlib.md5(data_str.encode()).hexdigest()[:8], 16)
        rng = np.random.RandomState(seed)
        return rng.randn(128).astype(np.float32)
    else:
        return np.random.random(128).astype(np.float32)

# 6. æ”¹è¿›çš„å›¾ç‰‡åµŒå…¥å‡½æ•°ï¼ˆå…¼å®¹ä¸åŒPyTorchç‰ˆæœ¬ï¼‰
def get_image_embedding(image_path, model=None):
    """å…¼å®¹ä¸åŒPyTorchç‰ˆæœ¬çš„å›¾ç‰‡åµŒå…¥å‡½æ•°"""
    try:
        import torch
        from PIL import Image
        import torchvision.transforms as transforms
        import torchvision
        
        if model is None:
            # åŠ¨æ€åŠ è½½æ¨¡å‹ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„torchvision
            try:
                # å°è¯•ä½¿ç”¨æ–°ç‰ˆæœ¬çš„weightså‚æ•°
                if hasattr(torchvision.models, 'ResNet50_Weights'):
                    weights = torchvision.models.ResNet50_Weights.DEFAULT
                    model = torchvision.models.resnet50(weights=weights)
                else:
                    # æ—§ç‰ˆæœ¬å…¼å®¹
                    model = torchvision.models.resnet50(pretrained=True)
            except Exception as e:
                logger.warning(f"ResNet50åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
                model = torchvision.models.resnet50(pretrained=False)
        
        # æ›¿æ¢å…¨è¿æ¥å±‚
        model.fc = Identity()
        model.eval()
        
        # å›¾åƒé¢„å¤„ç†ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬ï¼‰
        transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        # åŠ è½½å’Œå¤„ç†å›¾åƒ
        try:
            image = Image.open(image_path).convert('RGB')
        except Exception as e:
            logger.warning(f"å›¾åƒåŠ è½½å¤±è´¥ {image_path}: {e}ï¼Œä½¿ç”¨éšæœºå‘é‡")
            return np.random.random(2048).astype(np.float32)
        
        image_tensor = transform(image).unsqueeze(0)
        
        # ä½¿ç”¨GPUå¦‚æœå¯ç”¨
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model.to(device)
        image_tensor = image_tensor.to(device)
        
        with torch.no_grad():
            embedding = model(image_tensor)
        
        return embedding.cpu().squeeze().numpy().astype(np.float32)
        
    except Exception as e:
        logger.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {e}")
        # è¿”å›éšæœºå‘é‡ä½œä¸ºå¤‡ç”¨
        return np.random.random(2048).astype(np.float32)

# 7. å¤‡ç”¨å›¾ç‰‡åµŒå…¥å‡½æ•°
def get_image_embedding_backup(image_path, dim=2048):
    """å½“ä¸»è¦æ–¹æ³•å¤±è´¥æ—¶ä½¿ç”¨çš„å¤‡ç”¨å›¾ç‰‡åµŒå…¥"""
    logger.info(f"ä½¿ç”¨å¤‡ç”¨å›¾ç‰‡ç¼–ç æ–¹æ¡ˆ: {image_path}")
    # åŸºäºæ–‡ä»¶è·¯å¾„ç”Ÿæˆç¡®å®šæ€§éšæœºå‘é‡
    import hashlib
    seed = int(hashlib.md5(image_path.encode()).hexdigest()[:8], 16)
    rng = np.random.RandomState(seed)
    return rng.randn(dim).astype(np.float32)

# 8. åˆ›å»ºé›†åˆæ¨¡å¼
def create_collection_schema():
    """åˆ›å»ºå¤šæ¨¡æ€é›†åˆçš„æ¨¡å¼"""
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
        FieldSchema(name="text_vector", dtype=DataType.FLOAT_VECTOR, dim=384),
        FieldSchema(name="tabular_vector", dtype=DataType.FLOAT_VECTOR, dim=128),
        FieldSchema(name="image_vector", dtype=DataType.FLOAT_VECTOR, dim=2048),
        FieldSchema(name="metadata", dtype=DataType.VARCHAR, max_length=500)
    ]
    
    schema = CollectionSchema(fields, "å¤šæ¨¡æ€æ•°æ®é›†åˆ")
    return schema

# 9. æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
def collection_exists(collection_name):
    """æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨"""
    try:
        return collection_name in utility.list_collections()
    except Exception as e:
        logger.error(f"æ£€æŸ¥é›†åˆå­˜åœ¨æ€§å¤±è´¥: {e}")
        return False

# 10. ä¸»ç¨‹åº
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    logger.info("ğŸš€ å¼€å§‹å¤šæ¨¡æ€Milvusç¤ºä¾‹ç¨‹åº")
    
    # è®¾ç½®ç¯å¢ƒ
    text_encoder = setup_environment()
    
    # è¿æ¥åˆ°Milvus
    try:
        connections.connect("default", host="172.18.6.60", port="19530")
        logger.info("âœ… æˆåŠŸè¿æ¥åˆ°Milvus")
    except Exception as e:
        logger.error(f"âŒ è¿æ¥Milvuså¤±è´¥: {e}")
        return
    
    # é›†åˆåç§°
    collection_name = "multimodal_collection"
    
    # æ¸…ç†ç°æœ‰é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if collection_exists(collection_name):
        try:
            col = Collection(name=collection_name)
            col.drop()
            logger.info(f"âœ… å·²åˆ é™¤ç°æœ‰é›†åˆ: {collection_name}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤é›†åˆå¤±è´¥: {e}")
            return
    
    # åˆ›å»ºæ–°é›†åˆ
    try:
        schema = create_collection_schema()
        collection = Collection(name=collection_name, schema=schema)
        logger.info(f"âœ… æˆåŠŸåˆ›å»ºé›†åˆ: {collection_name}")
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºé›†åˆå¤±è´¥: {e}")
        return
    
    # å‡†å¤‡ç¤ºä¾‹æ•°æ®
    texts = [
        "è¿™æ˜¯ä¸€ä¸ªæ–‡æœ¬ç¤ºä¾‹ï¼Œå±•ç¤ºäººå·¥æ™ºèƒ½çš„åº”ç”¨ã€‚",
        "è¿™æ˜¯å¦ä¸€ä¸ªæ–‡æœ¬ç¤ºä¾‹ï¼Œè®¨è®ºæœºå™¨å­¦ä¹ çš„æœªæ¥ã€‚",
        "ç¬¬ä¸‰ä¸ªç¤ºä¾‹æ–‡æœ¬ï¼Œå…³äºæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œã€‚"
    ]
    
    tabular_data = [
        {"feature1": 0.5, "feature2": 0.3, "category": "A"},
        {"feature1": 0.7, "feature2": 0.9, "category": "B"},
        {"feature1": 0.2, "feature2": 0.8, "category": "A"}
    ]
    
    # å›¾åƒè·¯å¾„ - å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
    image_paths = [
        "./data/page_4.png",
        "./data/page_8.png", 
        "./data/sample_image.jpg"  # å¤‡ç”¨è·¯å¾„
    ]
    
    ids = [1, 2, 3]
    metadata = [
        "æ–‡æœ¬å’Œå›¾åƒæ•°æ®ç¤ºä¾‹1",
        "æ–‡æœ¬å’Œå›¾åƒæ•°æ®ç¤ºä¾‹2", 
        "æ–‡æœ¬å’Œå›¾åƒæ•°æ®ç¤ºä¾‹3"
    ]
    
    # å¤„ç†æ•°æ®
    logger.info("ğŸ“Š å¼€å§‹å¤„ç†å¤šæ¨¡æ€æ•°æ®...")
    
    text_embeddings = []
    tabular_embeddings = []
    image_embeddings = []
    
    for i, text in enumerate(texts):
        # æ–‡æœ¬åµŒå…¥
        text_embedding = get_text_embedding(text, text_encoder)
        text_embeddings.append(text_embedding)
        
        # è¡¨æ ¼åµŒå…¥
        tabular_embedding = get_tabular_embedding(tabular_data[i], method="hash_based")
        tabular_embeddings.append(tabular_embedding)
        
        # å›¾åƒåµŒå…¥ï¼ˆå¸¦é”™è¯¯å¤„ç†ï¼‰
        image_path = image_paths[i] if i < len(image_paths) else image_paths[0]
        if os.path.exists(image_path):
            try:
                image_embedding = get_image_embedding(image_path)
            except Exception as e:
                logger.warning(f"ä¸»è¦å›¾ç‰‡ç¼–ç å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
                image_embedding = get_image_embedding_backup(image_path)
        else:
            logger.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            image_embedding = get_image_embedding_backup(image_path)
        
        image_embeddings.append(image_embedding)
        
        logger.info(f"âœ… å¤„ç†å®Œæˆç¬¬ {i+1} æ¡æ•°æ®")
    
    # æ’å…¥æ•°æ®åˆ°é›†åˆ
    try:
        collection.insert([ids, text_embeddings, tabular_embeddings, image_embeddings, metadata])
        collection.flush()
        logger.info(f"âœ… æˆåŠŸæ’å…¥ {len(ids)} æ¡æ•°æ®")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ’å…¥å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºç´¢å¼•
    try:
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 1024}
        }
        
        collection.create_index(field_name="text_vector", index_params=index_params)
        collection.create_index(field_name="tabular_vector", index_params=index_params)
        collection.create_index(field_name="image_vector", index_params=index_params)
        logger.info("âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åŠ è½½é›†åˆ
    try:
        collection.load()
        logger.info(f"âœ… é›†åˆåŠ è½½æˆåŠŸï¼Œå®ä½“æ•°é‡: {collection.num_entities}")
    except Exception as e:
        logger.error(f"âŒ é›†åˆåŠ è½½å¤±è´¥: {e}")
        return
    
    # æ‰§è¡Œæœç´¢æµ‹è¯•
    logger.info("ğŸ” å¼€å§‹æœç´¢æµ‹è¯•...")
    
    # æ–‡æœ¬æœç´¢
    try:
        search_text = "äººå·¥æ™ºèƒ½"
        search_embedding = get_text_embedding(search_text, text_encoder).reshape(1, -1)
        
        results = collection.search(
            search_embedding, 
            "text_vector", 
            {"metric_type": "L2", "params": {"nprobe": 10}}, 
            limit=2,
            output_fields=["metadata"]
        )
        
        logger.info("ğŸ“ æ–‡æœ¬æœç´¢ç»“æœ:")
        for i, hit in enumerate(results[0]):
            logger.info(f"  æ’å {i+1}: ID={hit.id}, è·ç¦»={hit.distance:.4f}, å…ƒæ•°æ®={hit.entity.get('metadata')}")
    except Exception as e:
        logger.error(f"âŒ æ–‡æœ¬æœç´¢å¤±è´¥: {e}")
    
    # å›¾åƒæœç´¢ï¼ˆä½¿ç”¨ç¬¬ä¸€æ¡æ•°æ®çš„å›¾åƒå‘é‡ï¼‰
    try:
        if len(image_embeddings) > 0:
            search_image_embedding = np.array([image_embeddings[0]])
            
            results = collection.search(
                search_image_embedding,
                "image_vector",
                {"metric_type": "L2", "params": {"nprobe": 10}},
                limit=2,
                output_fields=["metadata"]
            )
            
            logger.info("ğŸ–¼ï¸ å›¾åƒæœç´¢ç»“æœ:")
            for i, hit in enumerate(results[0]):
                logger.info(f"  æ’å {i+1}: ID={hit.id}, è·ç¦»={hit.distance:.4f}, å…ƒæ•°æ®={hit.entity.get('metadata')}")
    except Exception as e:
        logger.error(f"âŒ å›¾åƒæœç´¢å¤±è´¥: {e}")
    
    # æ€§èƒ½ç»Ÿè®¡
    logger.info("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
    logger.info(f"  - æ–‡æœ¬å‘é‡ç»´åº¦: {len(text_embeddings[0]) if text_embeddings else 'N/A'}")
    logger.info(f"  - è¡¨æ ¼å‘é‡ç»´åº¦: {len(tabular_embeddings[0]) if tabular_embeddings else 'N/A'}")
    logger.info(f"  - å›¾åƒå‘é‡ç»´åº¦: {len(image_embeddings[0]) if image_embeddings else 'N/A'}")
    logger.info(f"  - æ€»æ•°æ®é‡: {collection.num_entities}")
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    # æ·»åŠ torchå¯¼å…¥ï¼ˆåœ¨æ–‡ä»¶é¡¶éƒ¨å·²å®šä¹‰ï¼Œè¿™é‡Œç¡®ä¿å¯ç”¨ï¼‰
    try:
        import torch
        import torch.nn as nn
    except ImportError:
        # å¦‚æœtorchä¸å¯ç”¨ï¼Œå®šä¹‰ç©ºçš„nnæ¨¡å—
        class nn:
            class Module:
                pass
        
        logger.warning("PyTorch nnæ¨¡å—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬")
    
    main()
