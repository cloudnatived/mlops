
ä¸€ã€ä¸ºä»€ä¹ˆé€‰æ‹©DeepSeek+Difyé»„é‡‘ç»„åˆï¼Ÿ
1.1 ä¼ä¸šçº§éƒ¨ç½²ä¸‰å¤§åˆšéœ€è§£å†³æ–¹æ¡ˆï¼š
1ï¸âƒ£ å®‰å…¨é—­ç¯ï¼šæœ¬åœ°ç¦»çº¿éƒ¨ç½²+æ•°æ®ç‰©ç†éš”ç¦»
2ï¸âƒ£ æˆæœ¬é©å‘½ï¼š16Gæ˜¾å­˜å³å¯è¿è¡Œ7Bæ¨¡å‹
3ï¸âƒ£ æ•æ·å¼€å‘ï¼šå¯è§†åŒ–å·¥ä½œæµ10åˆ†é’Ÿæ­å»ºAIåº”ç”¨

1.2 å…¸å‹åº”ç”¨åœºæ™¯ï¼š
âœ” é‡‘èé¢†åŸŸæ™ºèƒ½å®¢æœ
âœ” åŒ»ç–—æ•°æ®éšç§åˆ†æ
âœ” æ•™è‚²è¡Œä¸šå®šåˆ¶åŒ–æ•™å­¦
âœ” åˆ¶é€ ä¸šçŸ¥è¯†åº“ç®¡ç†

äºŒã€éƒ¨ç½²ç¯å¢ƒå‡†å¤‡æŒ‡å—
é™„Windows/Mac/Linuxå…¨å¹³å°é…ç½®æ–¹æ¡ˆ


| ç»„ä»¶ | æœ€ä½é…ç½®         | æ¨èé…ç½®  |
| ---- | ---------------- | --------- |
| GPU  | NVIDIA T4 (å¯é€‰) | RTX 4090  |
| æ˜¾å­˜ | 16GB             | 24GB      |
| å†…å­˜ | 16GB DDR4        | 32GB DDR5 |
| å­˜å‚¨ | 50GB SSD         | 1TB NVMe  |


2.1 ç¡¬ä»¶é…ç½®è¯´æ˜
1. ç¡¬ä»¶é…ç½®æ¸…å•
âœ… æœ€ä½é…ç½®ï¼š
CPUï¼š2æ ¸ä»¥ä¸Šï¼ˆæ¨èIntel Xeonç³»åˆ—ï¼‰
å†…å­˜ï¼š16GB DDR4
GPUï¼šNVIDIA T4ï¼ˆå¯é€‰ï¼‰
å­˜å‚¨ï¼š50GB SSD
âœ… æ¨èé…ç½®ï¼š
CPUï¼š4æ ¸+ï¼ˆAMD EPYCç³»åˆ—ï¼‰
æ˜¾å­˜ï¼š24GBï¼ˆRTX 4090ï¼‰
å†…å­˜ï¼š32GB DDR5
ç½‘ç»œï¼šåƒå…†å†…ç½‘

âœ… æœ¬æ¬¡å®éªŒé…ç½®ï¼š
CPUï¼š Intel(R) Xeon(R) CPU E5-2696 v4 @ 2.20GHz
æ˜¾å­˜ï¼š16GBï¼ˆTesla V100-PCIE-16GBï¼‰ * 3
å†…å­˜ï¼š256GB DDR4
ç½‘ç»œï¼šåƒå…†å†…ç½‘

2. è½¯ä»¶ç¯å¢ƒå…¨æ”»ç•¥
ğŸ“¦ å¿…è£…ç»„ä»¶ï¼š
â€¢ Docker 24.0+
â€¢ Docker Compose 2.20+
â€¢ Ollama 0.5.5+
â€¢ Nvidiaé©±åŠ¨535+ï¼ˆGPUåŠ é€Ÿéœ€CUDA 12ï¼‰
ğŸ’» å¤šå¹³å°å®‰è£…è¦ç‚¹ï¼š

```
# Linuxä¸“é¡¹é…ç½®ï¼ˆUbuntuç¤ºä¾‹ï¼‰
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Windowsç‰¹åˆ«æç¤º
éœ€å¯ç”¨WSL2å¹¶è®¾ç½®å†…å­˜é™åˆ¶ï¼š
[wsl2]
memory=16GB
swap=0
ä¸‰ã€éƒ¨ç½²æ ¸å¿ƒç»„ä»¶ï¼ˆå«è·¯å¾„/ç«¯å£å®šåˆ¶ï¼‰
3.1 Ollama é…ç½®
1. Ollamaæ·±åº¦é…ç½®
# è‡ªå®šä¹‰å®‰è£…è·¯å¾„ï¼ˆä»¥/dataä¸ºä¾‹ï¼‰
mkdir -p /data/ollama && export OLLAMA_MODELS="/data/ollama/models"

# å¯åŠ¨æœåŠ¡æŒ‡å®šç«¯å£ï¼ˆé»˜è®¤11434ï¼‰
OLLAMA_HOST=0.0.0.0:11435 ollama serve &

# æ¨¡å‹ä¸‹è½½åŠ é€ŸæŠ€å·§
export OLLAMA_MIRROR="https://mirror.example.com"
ollama run deepseek-r1:7b

# å›½å†…é•œåƒæºé…ç½®ï¼ˆé€Ÿåº¦æå‡10å€+ï¼‰
export OLLAMA_MIRROR=https://mirror.ghproxy.com/
ollama run deepseek-r1:7b
2. é¿å‘ç‰ˆOllamaå®‰è£…
# Windowsç‰¹åˆ«ç‰ˆï¼ˆè§£å†³è·¯å¾„å«ä¸­æ–‡é—®é¢˜ï¼‰
setx OLLAMA_MODELS "D:\ollama_models"
curl -L https://ollama.com/download/OllamaSetup_zh.exe -o ollama.exe
./ollama.exe
# å‡ºç°å®‰å…¨æç¤ºæ—¶é€‰æ‹©"å…è®¸æ‰€æœ‰è¿æ¥"

# Mac/Linuxä¸€é”®è„šæœ¬ï¼ˆå·²å¤„ç†æƒé™é—®é¢˜ï¼‰
curl -fsSL https://ollama.com/install.sh | sudo env PATH=$PATH sh
sudo systemctl enable ollama
3. ç»„ä»¶è¿é€šæ€§æµ‹è¯•
# éªŒè¯OllamaæœåŠ¡
curl http://localhost:11434/api/tags

# æ£€æŸ¥Difyå®¹å™¨
docker exec -it dify-api bash
ping host.docker.internal
3.2 Dify éƒ¨ç½²æ–¹æ¡ˆ
1. Difyé«˜çº§éƒ¨ç½²æ–¹æ¡ˆ
# æŒ‡å®šéƒ¨ç½²è·¯å¾„ï¼ˆåŸdockerç›®å½•å¯è‡ªå®šä¹‰ï¼‰
git clone https://github.com/langgenius/dify.git /opt/ai-platform/dify
cd /opt/ai-platform/dify/docker


# å°ç¼–è‡ªå®šä¹‰è·¯å¾„ä¸º /data1/home/datascience/item/ai-platform/dify


# å…³é”®é…ç½®æ–‡ä»¶ä¿®æ”¹ï¼ˆ.envç¤ºä¾‹ï¼‰
vim .env
---
# ç«¯å£ç»‘å®šè®¾ç½®
HTTP_PORT=8080
WEBSOCKET_PORT=8081

# æ•°æ®æŒä¹…åŒ–è·¯å¾„
DATA_DIR=/data1/home/datascience/item/ai-platform/dify_data

# å¯åŠ¨å‘½ä»¤ï¼ˆåå°è¿è¡Œï¼‰
docker compose up -d --build
image.png
image.png
difyè·¯å¾„ä½ç½®

image.png
image.png
å¯åŠ¨difyå®¹å™¨

image.png
image.png
åœ¨è¿™ä¸ªè¾“å‡ºä¸­ï¼Œä½ åº”è¯¥å¯ä»¥çœ‹åˆ°åŒ…æ‹¬ 3 ä¸ªä¸šåŠ¡æœåŠ¡ api / worker / webï¼Œä»¥åŠ 6 ä¸ªåŸºç¡€ç»„ä»¶ weaviate / db / redis / nginx / ssrf_proxy / sandbox ã€‚

image.png
image.png
é¦–å…ˆè®¿é—®åœ°å€,è¿›è¡Œåˆå§‹åŒ–é…ç½®ï¼Œè®°å¾—æ›¿æ¢ä¸ºä½ çš„ipå’Œç«¯å£ï¼Œè¿™é‡Œé…ç½®çš„ç¬¬ä¸€ä¸ªé»˜è®¤è´¦å·ä¸ºè¶…çº§ç®¡ç†å‘˜ï¼Œåˆ‡è®°æ³¨æ„ä¿å­˜ã€‚

image.png
image.png
è¾“å…¥è´¦å·å¯†ç ï¼Œç™»å½•difyï¼Œè¿›å…¥é…ç½®

image.png
image.png
3.3 Difyå¹³å°æ·±åº¦é›†æˆæŒ‡å—
1. æ¨¡å‹æ¥å…¥å…³é”®æ­¥éª¤
ğŸ“ è·¯å¾„ï¼šè®¾ç½® > æ¨¡å‹ä¾›åº”å•† > Ollama
ğŸ”§ é…ç½®å‚æ•°è¯¦è§£ï¼š
Model Nameï¼šdeepseek-r1:7bï¼ˆéœ€ä¸Ollamaæ¨¡å‹åå®Œå…¨ä¸€è‡´ï¼‰
Base URLï¼š
- ç‰©ç†æœºéƒ¨ç½²ï¼šhttp://ä¸»æœºIP:11434
- Dockerç½‘ç»œï¼šhttp://host.docker.internal:11434
Temperatureï¼š0.7ï¼ˆå¯¹è¯ç±»å»ºè®®0-1ï¼‰
Max Tokensï¼š4096ï¼ˆ7Bæ¨¡å‹å®æµ‹ä¸Šé™ï¼‰
image.png
image.png
ç‚¹å‡» ollama é€‰æ‹©å®‰è£…

image.png
image.png
ç‚¹å‡»æ·»åŠ æ¨¡å‹

image.png
image.png
å¼€å§‹æ·»åŠ LLMæ¨¡å‹ï¼Œè¾“å…¥æ¨¡å‹åç§°ï¼Œç±»å‹ï¼ŒURL ä¸ºéœ€è¦æ¥å…¥çš„æ¨¡å‹serverï¼Œä¾‹å¦‚æœ¬åœ°éƒ¨ç½²çš„deepseekï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥æ¥å…¥å…¶ä»–apiã€‚ä¾‹å¦‚deepseekå®˜ç½‘ï¼Œè±†åŒ…ï¼Œé€šä¹‰åƒé—®ç­‰ã€‚
image.png
image.png
3.4 åº”ç”¨åˆ›å»º
åˆ›å»ºç©ºç™½åº”ç”¨ï¼ŒèŠå¤©åŠ©æ‰‹ï¼Œå‘½åå¥½ä½ çš„åº”ç”¨åç§°

image.png
image.png
æµ‹è¯•AIåŠ©æ‰‹çš„ä½¿ç”¨ï¼Œæ­£å¸¸å¯¹è¯æŸ¥çœ‹æ¨¡å‹è°ƒç”¨

image.png
image.png
3.5 ä¼ä¸šçº§å®‰å…¨åŠ å›ºæ–¹æ¡ˆ
ğŸ”’ ä¼ è¾“åŠ å¯†ï¼š

# åå‘ä»£ç†é…ç½®ç¤ºä¾‹ï¼ˆNginxï¼‰
server {
    listen 443 ssl;
    server_name ai.example.com;
    
    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;
    
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
    }
}
3.6 å®æˆ˜æ¡ˆä¾‹ï¼š10åˆ†é’Ÿæ„å»ºæ™ºèƒ½å®¢æœç³»ç»Ÿ
1. åŸºç¡€ç‰ˆChatbotæ­å»º
[åˆ›å»ºåº”ç”¨] â†’ [å¯¹è¯å‹] â†’ å‘½å"DeepSeekå®¢æœåŠ©æ‰‹"
â†“
[æ¨¡å‹é€‰æ‹©] â†’ Ollama â†’ deepseek-r1:7b
â†“
[æç¤ºè¯å·¥ç¨‹]ï¼š
"ä½ æ˜¯ä¸€åä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œå›ç­”éœ€ç¬¦åˆä»¥ä¸‹è¦æ±‚ï¼š
1. ä½¿ç”¨{{ç”¨æˆ·è¯­è¨€}}åº”ç­”
2. å¼•ç”¨çŸ¥è¯†åº“ï¼š{{ä¸Šä¼ çš„PDFå†…å®¹}}
3. ç¦æ­¢é€éœ²æ¨¡å‹èº«ä»½"
2. é«˜çº§å·¥ä½œæµè®¾è®¡

å’¨è¯¢ç±»

æŠ€æœ¯é—®é¢˜





ç”¨æˆ·æé—®
æ„å›¾è¯†åˆ«
çŸ¥è¯†åº“æ£€ç´¢
è½¬æ¥API
ç”Ÿæˆå›å¤
æ•æ„Ÿè¯è¿‡æ»¤
è¿”å›ç»“æœ
3.7 é¿å‘å¤§å…¨ï¼šé«˜é¢‘é—®é¢˜è§£å†³æ–¹æ¡ˆ
1. ç«¯å£å†²çªç»ˆæå¤„ç†
# æŸ¥çœ‹ç«¯å£å ç”¨
lsof -i :11434

# æ‰¹é‡é‡Šæ”¾Difyèµ„æº
docker compose down --volumes --remove-orphans

# å¼ºåˆ¶é‡å»ºæœåŠ¡
docker compose up -d --force-recreate
2. æ¨¡å‹åŠ è½½å¼‚å¸¸æ’æŸ¥
# æŸ¥çœ‹Ollamaæ—¥å¿—
journalctl -u ollama -f

# éªŒè¯æ¨¡å‹å®Œæ•´æ€§
ollama ls
ollama show deepseek-r1:7b --modelfile
3. æ€§èƒ½ä¼˜åŒ–å‚æ•°ï¼ˆ7Bæ¨¡å‹å®æµ‹ï¼‰
# docker-composeè¦†ç›–é…ç½®
services:
  api:
    environment:
      - WORKER_COUNT=4
      - MODEL_LOAD_TIMEOUT=600
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 8G
 
```
